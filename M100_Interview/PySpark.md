# ğŸŒ¿ What is **Column Pruning** in PySpark?

**Column Pruning** is an optimization technique where **Spark reads only the columns required** for a computation â€” ignoring unnecessary columns from data sources like **Parquet**, **Delta**, **ORC**, etc.

This happens automatically in Spark's **Catalyst optimizer** as part of **lazy evaluation**.

---

## ğŸ”§ Why It Matters

âœ… **Performance Gains**:

* Reduces **I/O**: Less data is read from disk.
* Reduces **memory footprint**: Fewer columns in the DataFrame.
* Speeds up execution: Less data to shuffle or cache.

âœ… Especially useful for **wide tables** with dozens or hundreds of columns.

---

## ğŸ¯ Example

Assume a Parquet file with 10 columns (`id`, `name`, `email`, `country`, `status`, etc.):

```python
df = spark.read.parquet("/mnt/data/users")

# Column Pruning: only 2 columns are selected
df = df.select("id", "status")

df.show()
```

ğŸ”¥ **Spark only reads `id` and `status`** from disk â€” other columns are ignored entirely.

---

## ğŸ§  When Does Column Pruning Work Best?

| Format         | Supports Column Pruning?     |
| -------------- | ---------------------------- |
| **Parquet**    | âœ… Yes                        |
| **Delta Lake** | âœ… Yes                        |
| **ORC**        | âœ… Yes                        |
| **CSV / JSON** | âŒ No (must read all columns) |

âš ï¸ With **CSV/JSON**, Spark must read the whole file and then discard columns.

---

## ğŸ” How to Verify Column Pruning

Use `.explain()` to inspect the **physical plan**:

```python
df.select("id", "status").explain(True)
```

âœ… Youâ€™ll see only selected columns being scanned in the **physical plan** if pruning is applied.

---

## ğŸ’¡ Practical Tip

Avoid `select("*")` if you don't need all columns â€” it **prevents column pruning**:

```python
# âŒ BAD: reads all columns
df = spark.read.parquet("/mnt/data/users").select("*")

# âœ… GOOD: allows pruning
df = spark.read.parquet("/mnt/data/users").select("id", "status")
```

---

## âœ… Summary

| Feature           | Column Pruning                       |
| ----------------- | ------------------------------------ |
| Optimizes I/O     | âœ… Yes                                |
| Reduces Memory    | âœ… Yes                                |
| Automatic?        | âœ… If only necessary columns are used |
| Formats Supported | Parquet, ORC, Delta                  |

---

Would you like a Databricks notebook example with `.explain()` showing pruning in action?
