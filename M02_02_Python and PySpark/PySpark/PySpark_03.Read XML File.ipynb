{"cells":[{"cell_type":"markdown","source":["# Download from git and upload into lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"20cf42b1-61fc-42a3-be54-9391d9efbc72"},{"cell_type":"code","source":["import requests\n","\n","# 1️⃣ Paths\n","lakehouse_path = \"abfss://55732739-60eb-445b-94c4-65725b7190fa@onelake.dfs.fabric.microsoft.com/69019a9b-1026-430c-a874-1f18f5c21aa6/Files/emp.xml\"\n","github_url = \"https://raw.githubusercontent.com/rritec/Microsoft-Fabric/refs/heads/main/Labdata/emp.xml\"\n","# 2️⃣ Download JSON from GitHub\n","response = requests.get(github_url)\n","response.raise_for_status()\n","data = response.text\n","\n","# 3️⃣ Write JSON to Lakehouse\n","mssparkutils.fs.put(lakehouse_path, data, overwrite=True)\n","\n","print(\"✅ JSON successfully written to Lakehouse!\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"0da083a2-ac04-497b-ae3f-dfe53716692a","normalized_state":"finished","queued_time":"2026-02-03T01:15:04.2761483Z","session_start_time":null,"execution_start_time":"2026-02-03T01:15:04.2773409Z","execution_finish_time":"2026-02-03T01:15:05.2627131Z","parent_msg_id":"d23a43d2-53d9-4d4a-8b77-cbdfaca2e5fd"},"text/plain":"StatementMeta(, 0da083a2-ac04-497b-ae3f-dfe53716692a, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ JSON successfully written to Lakehouse!\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4fe2b6f-5128-4880-935f-e1db95170da1"},{"cell_type":"markdown","source":["# Read XML File"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2ec08036-a4ec-4c7c-9bd7-96ffeb513830"},{"cell_type":"code","source":["emp_df = spark.read \\\n","    .format(\"xml\") \\\n","    .option(\"rowTag\", \"employee\") \\\n","    .load(\"Files/emp.xml\")\n","\n","emp_df.show()\n","emp_df.printSchema()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"0da083a2-ac04-497b-ae3f-dfe53716692a","normalized_state":"finished","queued_time":"2026-02-03T01:15:23.9206166Z","session_start_time":null,"execution_start_time":"2026-02-03T01:15:23.9217182Z","execution_finish_time":"2026-02-03T01:15:26.4954084Z","parent_msg_id":"61c9645f-d977-47fe-9343-f7431d77d270"},"text/plain":"StatementMeta(, 0da083a2-ac04-497b-ae3f-dfe53716692a, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+----+------+-----+------+---------+---------+----+----+\n|comm|deptno|empno| ename| hiredate|      job| mgr| sal|\n+----+------+-----+------+---------+---------+----+----+\n|NULL|    20| 7369| SMITH|17-Dec-80|    CLERK|7902| 800|\n|NULL|    30| 7900| JAMES| 3-Dec-81|    CLERK|7698| 950|\n|NULL|    20| 7876| ADAMS|23-May-87|    CLERK|7788|1000|\n| 500|    30| 7521|  WARD|22-Feb-81| SALESMAN|7698|1250|\n|1400|    30| 7654|MARTIN|28-Sep-81| SALESMAN|7698|1250|\n|NULL|    10| 7934|MILLER|23-Jan-82|    CLERK|7782|1300|\n|   0|    30| 7844|TURNER| 8-Sep-81| SALESMAN|7698|1500|\n| 300|    30| 7499| ALLEN|20-Feb-81| SALESMAN|7698|1600|\n|NULL|    10| 7782| CLARK| 9-Jun-81|  MANAGER|7839|2450|\n|NULL|    30| 7698| BLAKE| 1-May-81|  MANAGER|7839|2850|\n|NULL|    20| 7566| JONES| 2-Apr-81|  MANAGER|7839|2975|\n|NULL|    20| 7788| SCOTT|19-Apr-87|  ANALYST|7566|3000|\n|NULL|    20| 7902|  FORD| 3-Dec-81|  ANALYST|7566|3000|\n|NULL|    10| 7839|  KING|17-Nov-81|PRESIDENT|NULL|5000|\n|NULL|    50| 7839|   Ram|17-Nov-81|      CFO|NULL|5000|\n+----+------+-----+------+---------+---------+----+----+\n\nroot\n |-- comm: long (nullable = true)\n |-- deptno: long (nullable = true)\n |-- empno: long (nullable = true)\n |-- ename: string (nullable = true)\n |-- hiredate: string (nullable = true)\n |-- job: string (nullable = true)\n |-- mgr: long (nullable = true)\n |-- sal: long (nullable = true)\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"15a66334-7643-4bd9-b7d5-4b95c8cad0b9"},{"cell_type":"markdown","source":["# Best Way to read file with required data by defining datatypes"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"342c16e7-3ec5-451a-8622-c22278a32b70"},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n","\n","schema = StructType([\n","    StructField(\"empno\", IntegerType(), True),\n","    StructField(\"ename\", StringType(), True),\n","    StructField(\"sal\", IntegerType(), True),\n","    StructField(\"deptno\", IntegerType(), True)\n","])\n","\n","emp_df = spark.read \\\n","    .format(\"xml\") \\\n","    .option(\"rowTag\", \"employee\") \\\n","    .schema(schema) \\\n","    .load(\"Files/emp.xml\")\n","\n","emp_df.show()\n","emp_df.printSchema()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"0da083a2-ac04-497b-ae3f-dfe53716692a","normalized_state":"finished","queued_time":"2026-02-03T01:16:44.5374626Z","session_start_time":null,"execution_start_time":"2026-02-03T01:16:44.5386049Z","execution_finish_time":"2026-02-03T01:16:45.3377264Z","parent_msg_id":"03057060-220a-4425-8c5d-e1df223e7d89"},"text/plain":"StatementMeta(, 0da083a2-ac04-497b-ae3f-dfe53716692a, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+------+----+------+\n|empno| ename| sal|deptno|\n+-----+------+----+------+\n| 7369| SMITH| 800|    20|\n| 7900| JAMES| 950|    30|\n| 7876| ADAMS|1000|    20|\n| 7521|  WARD|1250|    30|\n| 7654|MARTIN|1250|    30|\n| 7934|MILLER|1300|    10|\n| 7844|TURNER|1500|    30|\n| 7499| ALLEN|1600|    30|\n| 7782| CLARK|2450|    10|\n| 7698| BLAKE|2850|    30|\n| 7566| JONES|2975|    20|\n| 7788| SCOTT|3000|    20|\n| 7902|  FORD|3000|    20|\n| 7839|  KING|5000|    10|\n| 7839|   Ram|5000|    50|\n+-----+------+----+------+\n\nroot\n |-- empno: integer (nullable = true)\n |-- ename: string (nullable = true)\n |-- sal: integer (nullable = true)\n |-- deptno: integer (nullable = true)\n\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"619d05bb-61ed-4c28-90d0-a559bf108de2"},{"cell_type":"code","source":["emp_df.write \\\n","    .mode(\"overwrite\") \\\n","    .format(\"delta\") \\\n","    .save(\"Tables/dbo/emp_delta_xml\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"0da083a2-ac04-497b-ae3f-dfe53716692a","normalized_state":"finished","queued_time":"2026-02-03T01:17:41.0022815Z","session_start_time":null,"execution_start_time":"2026-02-03T01:17:41.0034461Z","execution_finish_time":"2026-02-03T01:17:54.431154Z","parent_msg_id":"3c6a6928-85de-4e44-ae3c-db3122369ad7"},"text/plain":"StatementMeta(, 0da083a2-ac04-497b-ae3f-dfe53716692a, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"866ee52c-9b74-4083-b7bc-2b1b12bfaa7a"},{"cell_type":"markdown","source":["# Q&A"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8c3f6eac-9bf0-46fc-b456-00923de82a3e"},{"cell_type":"markdown","source":["## MCQs: Reading XML Data in Microsoft Fabric\n","\n","1. **Which Microsoft Fabric engine natively supports reading XML files?**  \n","   - A. SQL Analytics Endpoint  \n","   - B. Data Warehouse  \n","   - C. Spark (Lakehouse Notebook)  \n","   - D. KQL Database  \n","   **Answer:** C  \n","\n","2. **Which option is mandatory when reading XML files using Spark in Microsoft Fabric?**  \n","   - A. rootTag  \n","   - B. rowTag  \n","   - C. inferSchema  \n","   - D. header  \n","   **Answer:** B  \n","\n","3. **Where should XML files be stored before being read by Spark in Fabric?**  \n","   - A. Azure SQL Database  \n","   - B. OneLake Lakehouse `Files` area  \n","   - C. SQL Analytics tables  \n","   - D. Power BI datasets  \n","   **Answer:** B  \n","\n","4. **Which Spark API is used to read XML files in Microsoft Fabric?**  \n","   - A. `spark.read.csv()`  \n","   - B. `spark.read.json()`  \n","   - C. `spark.read.format(\"xml\")`  \n","   - D. `spark.read.loadXml()`  \n","   **Answer:** C  \n","\n","5. **Can the SQL Analytics Endpoint directly parse and read XML files from OneLake?**  \n","   - A. Yes  \n","   - B. No  \n","   - C. Only using external tables  \n","   - D. Only using views  \n","   **Answer:** B  \n","\n","6. **What is the recommended Fabric approach to make XML data available for SQL Analytics?**  \n","   - A. Load XML directly into SQL tables  \n","   - B. Convert XML to CSV manually  \n","   - C. Parse XML using Spark and write as Delta tables  \n","   - D. Use Power BI to transform XML  \n","   **Answer:** C  \n","\n","7. **Which file format is preferred in Microsoft Fabric after parsing XML for analytics?**  \n","   - A. XML  \n","   - B. CSV  \n","   - C. JSON  \n","   - D. Delta  \n","   **Answer:** D  \n","\n","8. **Why is providing an explicit schema recommended when reading XML in Fabric Spark?**  \n","   - A. XML does not support schema  \n","   - B. It improves security  \n","   - C. It improves performance and avoids schema drift  \n","   - D. It is mandatory in Fabric  \n","   **Answer:** C  \n","\n","9. **Which Fabric component can ingest XML files using a no-code approach but cannot parse them?**  \n","   - A. SQL Analytics Endpoint  \n","   - B. Data Pipeline  \n","   - C. Power BI  \n","   - D. KQL Database  \n","   **Answer:** B  \n","\n","10. **What happens if the `rowTag` option is not specified while reading an XML file in Spark?**  \n","    - A. Spark automatically infers it  \n","    - B. Only the first record is read  \n","    - C. Spark throws an error  \n","    - D. XML is treated as JSON  \n","    **Answer:** C  \n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3f9c2fa2-ca50-4649-9480-35e2d440d4b8"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4cf3095b-200b-4e5d-9fca-1f1e9a3b2f5a"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"89f90c32-4f6f-4bdc-b3f8-7f17fb6ee5dc"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"69019a9b-1026-430c-a874-1f18f5c21aa6","known_lakehouses":[{"id":"69019a9b-1026-430c-a874-1f18f5c21aa6"}],"default_lakehouse_name":"RamReddyMyla","default_lakehouse_workspace_id":"55732739-60eb-445b-94c4-65725b7190fa"}}},"nbformat":4,"nbformat_minor":5}