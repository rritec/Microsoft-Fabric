{"cells":[{"cell_type":"markdown","source":["`Note: ` Above 4 exercise are just for practice purpose only \n","\n","`Rule 1:` For just data movement donot use notebooks(spark)\n","\n","`In Microsoft Fabric, for data ingestion, you should strictly use the Fabric Data Pipeline’s lakehouse or Files layer ingestion capabilities, typically via Copy Data or Data Flow activities. This ensures that raw data from sources like CSV, JSON, Parquet, or databases lands in the Bronze layer of the lakehouse in a reliable, schema-compliant, and versioned manner. Using these native Fabric ingestion methods guarantees scalability, lineage tracking, and compatibility`"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4e43d910-ce88-4e4a-b03d-cc3005901705"},{"cell_type":"markdown","source":["# 1️⃣ Read Bronze data"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1d595e2d-7d1f-4c8b-882f-8be1347f7fc8"},{"cell_type":"code","source":["from pyspark.sql.functions import (\n","    col, to_date, trim, coalesce, lit, when\n",")\n","\n","# Read Bronze data from Files\n","emp_bronze_df = (\n","    spark.read\n","         .option(\"header\", \"true\")\n","         .option(\"inferSchema\", \"true\")\n","         .csv(\"Files/bronze/emp.csv\")\n",")\n","\n","# Preview data (Git-friendly)\n","emp_bronze_df.printSchema()\n","emp_bronze_df.show(5)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"ca95096c-3642-46f2-8b3b-689d541a980f","normalized_state":"finished","queued_time":"2026-02-04T14:13:22.0168579Z","session_start_time":null,"execution_start_time":"2026-02-04T14:13:22.0179381Z","execution_finish_time":"2026-02-04T14:13:24.2574512Z","parent_msg_id":"689e8615-488e-40ba-bb62-a245651fe06c"},"text/plain":"StatementMeta(, ca95096c-3642-46f2-8b3b-689d541a980f, 15, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- empno: integer (nullable = true)\n |-- ename: string (nullable = true)\n |-- job: string (nullable = true)\n |-- mgr: integer (nullable = true)\n |-- hiredate: string (nullable = true)\n |-- sal: integer (nullable = true)\n |-- comm: integer (nullable = true)\n |-- deptno: integer (nullable = true)\n\n+-----+------+--------+----+---------+----+----+------+\n|empno| ename|     job| mgr| hiredate| sal|comm|deptno|\n+-----+------+--------+----+---------+----+----+------+\n| 7369| SMITH|   CLERK|7902|17-Dec-80| 800|NULL|    20|\n| 7900| JAMES|   CLERK|7698| 3-Dec-81| 950|NULL|    30|\n| 7876| ADAMS|   CLERK|7788|23-May-87|1000|NULL|    20|\n| 7521|  WARD|SALESMAN|7698|22-Feb-81|1250| 500|    30|\n| 7654|MARTIN|SALESMAN|7698|28-Sep-81|1250|1400|    30|\n+-----+------+--------+----+---------+----+----+------+\nonly showing top 5 rows\n\n"]}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5577112a-1bc7-4541-9896-f0e87c3bb06e"},{"cell_type":"markdown","source":["# 2️⃣ Apply Silver transformations"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c65c7f3f-2a48-4efc-a298-11fce4fb32ac"},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n","emp_silver_df = (\n","    emp_bronze_df\n","        # Convert hiredate string to DATE\n","        .withColumn(\n","            \"hiredate\",\n","            to_date(trim(col(\"hiredate\")), \"dd-MMM-yy\")\n","        )\n","        # Replace NULL commission with 0\n","        .withColumn(\n","            \"comm\",\n","            coalesce(col(\"comm\"), lit(0))\n","        )\n","        # Calculate total salary\n","        .withColumn(\n","            \"totalsal\",\n","            col(\"sal\") + col(\"comm\")\n","        )\n","        # Derive salary grade\n","        .withColumn(\n","            \"salgrade\",\n","            when(col(\"totalsal\") < 2000, \"LOW\")\n","            .when(col(\"totalsal\").between(2000, 3400), \"MEDIUM\")\n","            .otherwise(\"HIGH\")\n","        )\n",")\n","\n","# Preview transformed data\n","emp_silver_df.printSchema()\n","emp_silver_df.show(5)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"ca95096c-3642-46f2-8b3b-689d541a980f","normalized_state":"finished","queued_time":"2026-02-04T14:13:02.2268863Z","session_start_time":null,"execution_start_time":"2026-02-04T14:13:02.2281662Z","execution_finish_time":"2026-02-04T14:13:03.095342Z","parent_msg_id":"45cee6e5-d455-4dc7-961e-3d489de87a47"},"text/plain":"StatementMeta(, ca95096c-3642-46f2-8b3b-689d541a980f, 14, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- empno: integer (nullable = true)\n |-- ename: string (nullable = true)\n |-- job: string (nullable = true)\n |-- mgr: integer (nullable = true)\n |-- hiredate: date (nullable = true)\n |-- sal: integer (nullable = true)\n |-- comm: integer (nullable = false)\n |-- deptno: integer (nullable = true)\n |-- totalsal: integer (nullable = true)\n |-- salgrade: string (nullable = false)\n\n+-----+------+--------+----+----------+----+----+------+--------+--------+\n|empno| ename|     job| mgr|  hiredate| sal|comm|deptno|totalsal|salgrade|\n+-----+------+--------+----+----------+----+----+------+--------+--------+\n| 7369| SMITH|   CLERK|7902|1980-12-17| 800|   0|    20|     800|     LOW|\n| 7900| JAMES|   CLERK|7698|1981-12-03| 950|   0|    30|     950|     LOW|\n| 7876| ADAMS|   CLERK|7788|1987-05-23|1000|   0|    20|    1000|     LOW|\n| 7521|  WARD|SALESMAN|7698|1981-02-22|1250| 500|    30|    1750|     LOW|\n| 7654|MARTIN|SALESMAN|7698|1981-09-28|1250|1400|    30|    2650|  MEDIUM|\n+-----+------+--------+----+----------+----+----+------+--------+--------+\nonly showing top 5 rows\n\n"]}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"00edafa6-be7d-4125-b4ae-edeaa3f2b065"},{"cell_type":"markdown","source":["# 3️⃣ Enforce Silver schema"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6857a0e9-7dc3-4239-9105-11aa36fcb6df"},{"cell_type":"code","source":["from pyspark.sql.types import (\n","    StructType, StructField,\n","    IntegerType, StringType,\n","    DateType, DecimalType\n",")\n","\n","emp_silver_schema = StructType([\n","    StructField(\"empno\", IntegerType(), False),\n","    StructField(\"ename\", StringType(), False),\n","    StructField(\"job\", StringType(), False),\n","    StructField(\"mgr\", IntegerType(), True),\n","    StructField(\"hiredate\", DateType(), False),\n","    StructField(\"sal\", IntegerType(), False),\n","    StructField(\"comm\", IntegerType(), False),\n","    StructField(\"deptno\", IntegerType(), False),\n","    StructField(\"totalsal\", IntegerType(), False),\n","    StructField(\"salgrade\", StringType(), False)\n","])\n","\n","emp_silver_final_df = spark.createDataFrame(\n","    emp_silver_df.rdd,\n","    emp_silver_schema\n",")\n","\n","# Validate schema-applied data\n","emp_silver_final_df.printSchema()\n","emp_silver_final_df.show(5)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"ca95096c-3642-46f2-8b3b-689d541a980f","normalized_state":"finished","queued_time":"2026-02-04T14:12:38.2230649Z","session_start_time":null,"execution_start_time":"2026-02-04T14:12:38.2240801Z","execution_finish_time":"2026-02-04T14:12:39.1641613Z","parent_msg_id":"e1d55280-b796-4950-82c1-90793eb01c25"},"text/plain":"StatementMeta(, ca95096c-3642-46f2-8b3b-689d541a980f, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- empno: integer (nullable = false)\n |-- ename: string (nullable = false)\n |-- job: string (nullable = false)\n |-- mgr: integer (nullable = true)\n |-- hiredate: date (nullable = false)\n |-- sal: integer (nullable = false)\n |-- comm: integer (nullable = false)\n |-- deptno: integer (nullable = false)\n |-- totalsal: integer (nullable = false)\n |-- salgrade: string (nullable = false)\n\n+-----+------+--------+----+----------+----+----+------+--------+--------+\n|empno| ename|     job| mgr|  hiredate| sal|comm|deptno|totalsal|salgrade|\n+-----+------+--------+----+----------+----+----+------+--------+--------+\n| 7369| SMITH|   CLERK|7902|1980-12-17| 800|   0|    20|     800|     LOW|\n| 7900| JAMES|   CLERK|7698|1981-12-03| 950|   0|    30|     950|     LOW|\n| 7876| ADAMS|   CLERK|7788|1987-05-23|1000|   0|    20|    1000|     LOW|\n| 7521|  WARD|SALESMAN|7698|1981-02-22|1250| 500|    30|    1750|     LOW|\n| 7654|MARTIN|SALESMAN|7698|1981-09-28|1250|1400|    30|    2650|  MEDIUM|\n+-----+------+--------+----+----------+----+----+------+--------+--------+\nonly showing top 5 rows\n\n"]}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"56313fbe-5f4d-47c8-9f2f-134061e5692f"},{"cell_type":"markdown","source":["# 4️⃣ Write to Silver layer (Delta)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7884e6b9-870d-4b28-be6a-a2e748b7a1eb"},{"cell_type":"code","source":["emp_silver_final_df.write \\\n","    .format(\"delta\") \\\n","    .mode(\"overwrite\") \\\n","    .saveAsTable(\"silver.silver_emp\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"ca95096c-3642-46f2-8b3b-689d541a980f","normalized_state":"finished","queued_time":"2026-02-04T14:14:43.6397492Z","session_start_time":null,"execution_start_time":"2026-02-04T14:14:43.6408067Z","execution_finish_time":"2026-02-04T14:14:57.1997914Z","parent_msg_id":"e6833e31-94b0-4029-9d9d-f98139d9f412"},"text/plain":"StatementMeta(, ca95096c-3642-46f2-8b3b-689d541a980f, 17, Finished, Available, Finished)"},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"abec2557-fb16-4caa-a967-9ca2ee7adcb8"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"a375dc6e-2dd7-4a0c-a829-7e6bc66cb0a3","known_lakehouses":[{"id":"a375dc6e-2dd7-4a0c-a829-7e6bc66cb0a3"}],"default_lakehouse_name":"b2026_lakehouse","default_lakehouse_workspace_id":"55732739-60eb-445b-94c4-65725b7190fa"}}},"nbformat":4,"nbformat_minor":5}