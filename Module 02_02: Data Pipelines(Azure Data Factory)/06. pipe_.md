# üß™ Lakehouse to Fabric SQL Pipeline - Full Navigation Guide

This document serves as a step-by-step navigation and explanation for the `LakehouseToFabricSQL_CopyPipeline` built in Microsoft Fabric. The pipeline dynamically loads delimited text files from a Lakehouse folder into Fabric SQL tables using metadata from a JSON configuration file.

---

## üîÅ Pipeline Structure Overview

**Pipeline Name**: `LakehouseToFabricSQL_CopyPipeline`

**Purpose**:  
- To read a list of file-to-table mappings from a parameter JSON file.  
- For each mapping:
  - Check if the file exists in the Lakehouse.
  - If it exists, copy it to the corresponding Fabric SQL table using dynamic schema and table mapping.

---

## ‚öôÔ∏è Step-by-Step Activity Breakdown

---

### üß© 1. Activity: `ReadParameterFile`
- **Type**: `Lookup`
- **Description**: Reads a JSON parameter file from Lakehouse path `Files/rawdata/ParameterFile.json`.
- **Source Format**: JSON
- **Output**:  
  - `output.firstRow.srcs_tgts` ‚Üí Used in the ForEach activity.
- **Why**: Drives the pipeline loop dynamically with metadata.

---

### üîÅ 2. Activity: `LoopThroughSourceTargets`
- **Type**: `ForEach`
- **Input Items**: `@activity('ReadParameterFile').output.firstRow.srcs_tgts`
- **Execution Mode**: Sequential (`isSequential: true`)
- **Purpose**: Loops through each source-target file/table mapping from the parameter file.

---

### üìÅ 3. Activity (inside ForEach): `CheckIfFileExistsInLakehouse`
- **Type**: `GetMetadata`
- **Field Checked**: `exists`
- **Dataset Location**:
  - **FileName**: `@item().FileName`
  - **FolderPath**: `@item().FolderName`
- **Linked Service**: Lakehouse `rr_batch100`
- **Why**: Avoids copy operations on missing files by checking for their existence first.

---

### ‚ùì 4. Activity: `IfFileExists_ThenCopyToSQL`
- **Type**: `If Condition`
- **Condition**: `@activity('CheckIfFileExistsInLakehouse').output.exists`
- **Branching**:
  - **True Path** ‚Üí Executes the `CopyDelimitedFileToSQLTable` activity
  - **False Path** ‚Üí No action (empty)

---

### üì• 5. Activity (inside If True): `CopyDelimitedFileToSQLTable`
- **Type**: `Copy`
- **Source**:
  - Type: `DelimitedTextSource`
  - File/Folder: From `@item().FileName` and `@item().FolderName`
  - Format Settings: CSV, first row as header, comma-delimited
- **Sink**:
  - Type: `FabricSqlDatabaseSink`
  - Connection: `rritec`
  - Target Table: Uses dynamic mapping:
    - `@item().SchemaName` ‚Üí Schema
    - `@item().TableName` ‚Üí Table
  - Write Behavior: `insert`
  - Table Option: `autoCreate`
- **Translator**: `TabularTranslator`
  - Type conversion enabled
  - Allows truncation and disables Boolean-to-Number conversion
- **Why**: Loads each file into its mapped Fabric SQL table dynamically and efficiently.

---

## üìÅ Input Parameter File (`ParameterFile.json`)

**Location**: `Files/rawdata/ParameterFile.json`  
**Expected Schema Example**:
```json
{
  "srcs_tgts": [
    {
      "FileName": "employees.csv",
      "FolderName": "data/hr",
      "SchemaName": "hr",
      "TableName": "employees"
    },
    {
      "FileName": "departments.csv",
      "FolderName": "data/hr",
      "SchemaName": "hr",
      "TableName": "departments"
    }
  ]
}
