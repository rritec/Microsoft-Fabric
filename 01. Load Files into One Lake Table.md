# Load Files into One Lake Table
## Create Workspace
1. Go to app.powerbi.com > Click on **Workspace** > Create **New Workspace**
![image](https://github.com/rritec/dataFabric/assets/20516321/fc06467c-8cc8-4b8f-a098-28e11af105f7)



## Create OneLake
1. Click on **New** > Click on **More Options** > Click on **Lake House** > Name it as **rritecOneLake**
![image](https://github.com/rritec/dataFabric/assets/20516321/263d3de2-44ab-486b-af20-d970bf19d9fa)

## create folders and upload files
1. Click on **rritecOneLake** **>** Click on **Files ...** **>** Clcik on **New Sub Folder** **>** Name it as **study**
2. Click on **study ...** **>** Clcik on **New Sub Folder** **>>** Name it as **nbu**
2. Click on **study ...** > Clcik on **New Sub Folder** > Name it as **obu**
3. Click on **nbu ...** > Clcik on **upload** > Click on **upload Files** > Click on ![image](https://github.com/rritec/dataFabric/assets/20516321/c2b6c690-6eb4-4921-b7ca-0430a727f12d) > Select two Files emp.csv and dept.csv from **labdata** folder > click on **open** > click on **upload**
4. Click on **obu ...** > Clcik on **upload** > Click on **upload Files** > Click on ![image](https://github.com/rritec/dataFabric/assets/20516321/c2b6c690-6eb4-4921-b7ca-0430a727f12d) > Select two Files emp.csv and dept.csv from **labdata** folder > click on **open** > click on **upload**
![image](https://github.com/rritec/dataFabric/assets/20516321/eb948d3e-c404-4751-9251-cdcd69a4d64a)
![image](https://github.com/rritec/dataFabric/assets/20516321/317b4d55-6504-479c-8741-45dc75303c46)


## Create Notebook
1. Go Back to **rritecWorkSpace**
2. Click on **New** **>>** Click on **More Options** **>>** Click on **Notebook** **>>** Name it as **rritecNotebook**
3. Click on **Lakehouse** **>>** Click on **Add** **>>** Select **Existing Lakehouse** >> Click on **Add** >> Select **rritecOnelake** >> click on **Add**
4. Type below code
``` py
def get_required_file_recursively(file_path,file_name):
    list_of_files=[]
    for i in mssparkutils.fs.ls(file_path):
        #print(i.path)
        for i in mssparkutils.fs.ls(i.path):
            if i.name ==file_name:
                #print(i.path,i.name)
                list_of_files.append(i.path)
    return list_of_files
```
``` py
file_path="abfss://rritecWorkspace@onelake.dfs.fabric.microsoft.com/rritecOneLake.Lakehouse/Files/study"
file_name="emp.csv"
```
``` py
# Create a Delta Lake table
table_name = "my_emp_table"
for i in get_required_file_recursively(file_path,file_name):
    df = spark.read.option("header", "true").csv(i)
    df.write.format("delta").mode("append").option("overwriteSchema", "true").saveAsTable(table_name)
```
``` py
df = spark.sql("SELECT * FROM rritecOneLake.my_emp_table LIMIT 1000")
display(df)

```

## Create pipeline

1. Go to rritecworkspace > open notebook

![image](https://github.com/rritec/dataFabric/assets/20516321/58ac8519-1662-46b0-af8b-fd9a81257094)

2. In **home** click on pipeline symbol(beside data wrangler)

![image](https://github.com/rritec/dataFabric/assets/20516321/07cf1897-9acf-477a-a038-196f8fe42642)

3. Click on new pipeline > name the pipeline **pipeline_1** > click on settings. check**workspace** and **notebook**

![image](https://github.com/rritec/dataFabric/assets/20516321/baaa9755-73c4-465f-9ebf-cdc3f9bed132)

4. run the pipeline

![image](https://github.com/rritec/dataFabric/assets/20516321/1711f6a5-54a7-4587-9948-1ba7b200acad)

## Create PowerBI Report Using OneLack

1. Open **PowerBI Deskop** > click on **OneLake Data Hub Activity** > Select **Lakehouses**

![image](https://github.com/rritec/dataFabric/assets/20516321/f2781e3d-2258-4a3d-b4eb-93cb0656b2fa)

2. Select **bronze** OneLack > click on **connect dropdown** and select **connect to SQL endpoint**

![image](https://github.com/rritec/dataFabric/assets/20516321/09b7683d-cf54-4656-bc56-708e9f5bb71a)

3. Select **nbu_emp_csv** and click on **load**

![image](https://github.com/rritec/dataFabric/assets/20516321/354f3fa1-2562-4fe3-80ab-64f0cfdef89c)


4. Select **import** and click on **ok**

![image](https://github.com/rritec/dataFabric/assets/20516321/e41d5d91-aa76-4e4f-8ad5-1f7f51f9e069)

5. Select table in visualizations and select required columns

![image](https://github.com/rritec/dataFabric/assets/20516321/b5fb58c8-aecb-4b2a-a996-2154d01b1cdb)






 





