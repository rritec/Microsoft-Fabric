# Pipe_from_SqlDatabase_to_Lakehouse_deltaTable
---
## Step 1: Create SQL Database and create sample data.
- Go to the Workspace where you want to create your database.
- Click â€œ+ New itemâ€, then choose â€œSQL Databaseâ€
- Name your database (e.g., EmployeeDB) and click Create.


### ðŸ§° SQL Script: Create Tables + Insert Sample Data

```sql
-- Create department table
CREATE TABLE dept (
    dept_id INT PRIMARY KEY,
    dept_name VARCHAR(50)
);

-- Create employee table
CREATE TABLE emp (
    emp_id INT PRIMARY KEY,
    emp_name VARCHAR(100),
    hire_date DATE,
    salary DECIMAL(10, 2),
    dept_id INT,
    FOREIGN KEY (dept_id) REFERENCES dept(dept_id)
);

-- Insert sample records into dept
INSERT INTO dept (dept_id, dept_name) VALUES
(10, 'Sales'),
(20, 'Engineering'),
(30, 'HR');

-- Insert sample records into emp
INSERT INTO emp (emp_id, emp_name, hire_date, salary, dept_id) VALUES
(101, 'Alice Johnson', '2022-05-15', 72000.00, 20),
(102, 'Bob Smith', '2021-11-03', 68000.00, 10),
(103, 'Clara Martinez', '2023-01-10', 62000.00, 30),
(104, 'David Kim', '2020-08-20', 75000.00, 20);
```
---

## Step 2: Create data Pipeline
1. Log in to your Microsoft Fabric workspace.
2. Navigate to the **Data Pipelines** section.
1. In **New Pipeline** window > Give your pipeline a name, e.g., `Pipe_from_SqlDatabase_to_Lakehouse_deltaTable`.

---

## Step 3: Add  activity to the Pipeline

1. Add a **Copy Data** activity
2. Configure the following:
- **Source**:
  - Type: `FabricSqlDatabaseSource`
  - Query Timeout: `02:00:00`
  - Dataset: `FabricSqlDatabaseTable`
    - Schema: `dbo`
    - Table: `EMP`
- **Sink**:
  - Type: `LakehouseTableSink`
  - Table Action: `Append`
  - Dataset: `LakehouseTable`
    - Table Name: `emp20250411`

---

## Step 4: Review and Publish
1. Review the pipeline configuration to ensure all settings are correct.
2. Click **Publish** to deploy the pipeline.

---

## Additional Notes
- You can monitor the pipeline's execution and review logs for debugging.


---


